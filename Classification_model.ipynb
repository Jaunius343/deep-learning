{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(size=256),\n",
    "    transforms.CenterCrop(size=224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Train Data : 1200\n",
      "Length of Test Data : 150\n",
      "Length of Validation Data : 150\n",
      "Classes: ['bird', 'car', 'house']\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.ImageFolder(\"./Data/train/dataset2/\", train_transform)\n",
    "test_dataset = datasets.ImageFolder(\"./Data/test/dataset2/\", test_transform)\n",
    "validation_dataset = datasets.ImageFolder(\"./Data/validation/dataset2/\", test_transform)\n",
    "\n",
    "print(f\"Length of Train Data : {len(train_dataset)}\")\n",
    "print(f\"Length of Test Data : {len(test_dataset)}\")\n",
    "print(f\"Length of Validation Data : {len(validation_dataset)}\")\n",
    "print(f\"Classes: {train_dataset.classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "num_workers = 10\n",
    "batch_size = 32\n",
    "\n",
    "print(num_workers)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, num_workers = num_workers, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = batch_size, num_workers = num_workers)\n",
    "validation_loadder = torch.utils.data.DataLoader(validation_dataset, batch_size = batch_size, num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "\n",
    "# Define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, in_shape, out_classes=3):\n",
    "      super().__init__()\n",
    "      self.network = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(in_shape[0], 32, kernel_size = 3, padding = 1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            # nn.Dropout(0.1),\n",
    "\n",
    "            nn.Conv2d(32,64, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            # nn.Dropout(0.1),\n",
    "\n",
    "            nn.Conv2d(64,128, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            # nn.Dropout(0.1),\n",
    "\n",
    "            nn.Conv2d(128,128, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            # nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Conv2d(128,256, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            # nn.Dropout(0.2),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * (in_shape[1]//32) * (in_shape[2]//32),1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, out_classes)\n",
    "        )\n",
    "      \n",
    "    def forward(self, x):\n",
    "      return self.network(x)\n",
    "    \n",
    "    def save(self, filename):\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(self.__dict__, f)\n",
    "\n",
    "    def load(self, filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            state = pickle.load(f)\n",
    "            self.__dict__.update(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def train(model, train_dataloader, test_dataloader, num_epochs=10, learning_rate=0.001):\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.001)\n",
    "\n",
    "    # Track the best validation accuracy\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # Train the model for num_epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Train the model for one epoch\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for images, labels in train_dataloader:\n",
    "            # Move the data to the GPU if available\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass and compute the loss\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and update the weights\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Compute the training accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Add the batch loss to the total loss\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "\n",
    "        # Compute the average training loss and accuracy for the epoch\n",
    "        train_loss = train_loss / len(train_dataloader.dataset)\n",
    "        train_acc = 100 * train_correct / train_total\n",
    "\n",
    "        print(f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}')\n",
    "\n",
    "        # Validate the model every 5 epochs\n",
    "        if (epoch+1) % 5 == 0:\n",
    "            # Evaluate the model on the validation set\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for images, labels in test_dataloader:\n",
    "                    # Move the data to the GPU if available\n",
    "                    images = images.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # Forward pass and compute the loss\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Compute the validation accuracy\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "                    # Add the batch loss to the total loss\n",
    "                    val_loss += loss.item() * images.size(0)\n",
    "\n",
    "            # Compute the average validation loss and accuracy for the epoch\n",
    "            val_loss = val_loss / len(test_dataloader.dataset)\n",
    "            val_acc = 100 * val_correct / val_total\n",
    "\n",
    "            print(f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}')\n",
    "\n",
    "            # Check if the current model has the best validation accuracy so far\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                torch.save(model.state_dict(), f'Data/params/best_model_tLoss{round(train_loss,2)}_tAcc{round(train_acc,2)}_vAcc{round(val_acc,2)}.pt')\n",
    "\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter count: 13,912,707\n"
     ]
    }
   ],
   "source": [
    "img_shape = train_dataset[0][0].shape\n",
    "model = Net(img_shape).to(device)\n",
    "print(f'Parameter count: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "Train Loss: 1.0563 | Train Acc: 45.67\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "Train Loss: 1.0158 | Train Acc: 51.75\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "Train Loss: 0.9306 | Train Acc: 56.42\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "Train Loss: 0.9174 | Train Acc: 57.33\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "Train Loss: 0.8575 | Train Acc: 61.83\n",
      "Val Loss: 0.7809 | Val Acc: 62.00\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "Train Loss: 0.8463 | Train Acc: 61.08\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "Train Loss: 0.8059 | Train Acc: 65.08\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "Train Loss: 0.7878 | Train Acc: 68.00\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "Train Loss: 0.7925 | Train Acc: 65.08\n",
      "\n",
      "Epoch 10/100\n",
      "----------\n",
      "Train Loss: 0.7590 | Train Acc: 67.17\n",
      "Val Loss: 1.1323 | Val Acc: 50.00\n",
      "\n",
      "Epoch 11/100\n",
      "----------\n",
      "Train Loss: 0.7124 | Train Acc: 68.50\n",
      "\n",
      "Epoch 12/100\n",
      "----------\n",
      "Train Loss: 0.7223 | Train Acc: 68.58\n",
      "\n",
      "Epoch 13/100\n",
      "----------\n",
      "Train Loss: 0.7053 | Train Acc: 71.08\n",
      "\n",
      "Epoch 14/100\n",
      "----------\n",
      "Train Loss: 0.6831 | Train Acc: 70.00\n",
      "\n",
      "Epoch 15/100\n",
      "----------\n",
      "Train Loss: 0.6848 | Train Acc: 70.25\n",
      "Val Loss: 0.6998 | Val Acc: 76.00\n",
      "\n",
      "Epoch 16/100\n",
      "----------\n",
      "Train Loss: 0.6733 | Train Acc: 70.33\n",
      "\n",
      "Epoch 17/100\n",
      "----------\n",
      "Train Loss: 0.6462 | Train Acc: 71.83\n",
      "\n",
      "Epoch 18/100\n",
      "----------\n",
      "Train Loss: 0.6088 | Train Acc: 75.17\n",
      "\n",
      "Epoch 19/100\n",
      "----------\n",
      "Train Loss: 0.6257 | Train Acc: 73.00\n",
      "\n",
      "Epoch 20/100\n",
      "----------\n",
      "Train Loss: 0.6073 | Train Acc: 75.00\n",
      "Val Loss: 0.7540 | Val Acc: 70.00\n",
      "\n",
      "Epoch 21/100\n",
      "----------\n",
      "Train Loss: 0.6158 | Train Acc: 74.25\n",
      "\n",
      "Epoch 22/100\n",
      "----------\n",
      "Train Loss: 0.5795 | Train Acc: 75.75\n",
      "\n",
      "Epoch 23/100\n",
      "----------\n",
      "Train Loss: 0.5377 | Train Acc: 78.00\n",
      "\n",
      "Epoch 24/100\n",
      "----------\n",
      "Train Loss: 0.5660 | Train Acc: 76.67\n",
      "\n",
      "Epoch 25/100\n",
      "----------\n",
      "Train Loss: 0.5239 | Train Acc: 79.25\n",
      "Val Loss: 0.6918 | Val Acc: 74.00\n",
      "\n",
      "Epoch 26/100\n",
      "----------\n",
      "Train Loss: 0.5327 | Train Acc: 78.00\n",
      "\n",
      "Epoch 27/100\n",
      "----------\n",
      "Train Loss: 0.5271 | Train Acc: 78.00\n",
      "\n",
      "Epoch 28/100\n",
      "----------\n",
      "Train Loss: 0.5339 | Train Acc: 77.58\n",
      "\n",
      "Epoch 29/100\n",
      "----------\n",
      "Train Loss: 0.5270 | Train Acc: 79.42\n",
      "\n",
      "Epoch 30/100\n",
      "----------\n",
      "Train Loss: 0.5075 | Train Acc: 79.50\n",
      "Val Loss: 0.6133 | Val Acc: 80.00\n",
      "\n",
      "Epoch 31/100\n",
      "----------\n",
      "Train Loss: 0.4664 | Train Acc: 81.67\n",
      "\n",
      "Epoch 32/100\n",
      "----------\n",
      "Train Loss: 0.5033 | Train Acc: 78.67\n",
      "\n",
      "Epoch 33/100\n",
      "----------\n",
      "Train Loss: 0.5083 | Train Acc: 77.58\n",
      "\n",
      "Epoch 34/100\n",
      "----------\n",
      "Train Loss: 0.4989 | Train Acc: 79.58\n",
      "\n",
      "Epoch 35/100\n",
      "----------\n",
      "Train Loss: 0.4615 | Train Acc: 80.92\n",
      "Val Loss: 0.6092 | Val Acc: 76.67\n",
      "\n",
      "Epoch 36/100\n",
      "----------\n",
      "Train Loss: 0.4976 | Train Acc: 77.92\n",
      "\n",
      "Epoch 37/100\n",
      "----------\n",
      "Train Loss: 0.4783 | Train Acc: 80.08\n",
      "\n",
      "Epoch 38/100\n",
      "----------\n",
      "Train Loss: 0.4761 | Train Acc: 81.25\n",
      "\n",
      "Epoch 39/100\n",
      "----------\n",
      "Train Loss: 0.4752 | Train Acc: 80.25\n",
      "\n",
      "Epoch 40/100\n",
      "----------\n",
      "Train Loss: 0.4744 | Train Acc: 79.83\n",
      "Val Loss: 0.5687 | Val Acc: 78.67\n",
      "\n",
      "Epoch 41/100\n",
      "----------\n",
      "Train Loss: 0.4424 | Train Acc: 81.83\n",
      "\n",
      "Epoch 42/100\n",
      "----------\n",
      "Train Loss: 0.4344 | Train Acc: 81.92\n",
      "\n",
      "Epoch 43/100\n",
      "----------\n",
      "Train Loss: 0.4763 | Train Acc: 81.00\n",
      "\n",
      "Epoch 44/100\n",
      "----------\n",
      "Train Loss: 0.4246 | Train Acc: 81.83\n",
      "\n",
      "Epoch 45/100\n",
      "----------\n",
      "Train Loss: 0.3987 | Train Acc: 84.75\n",
      "Val Loss: 0.5573 | Val Acc: 82.00\n",
      "\n",
      "Epoch 46/100\n",
      "----------\n",
      "Train Loss: 0.4398 | Train Acc: 82.33\n",
      "\n",
      "Epoch 47/100\n",
      "----------\n",
      "Train Loss: 0.4267 | Train Acc: 83.00\n",
      "\n",
      "Epoch 48/100\n",
      "----------\n",
      "Train Loss: 0.4263 | Train Acc: 82.58\n",
      "\n",
      "Epoch 49/100\n",
      "----------\n",
      "Train Loss: 0.4367 | Train Acc: 81.33\n",
      "\n",
      "Epoch 50/100\n",
      "----------\n",
      "Train Loss: 0.4496 | Train Acc: 81.08\n",
      "Val Loss: 0.5272 | Val Acc: 81.33\n",
      "\n",
      "Epoch 51/100\n",
      "----------\n",
      "Train Loss: 0.4398 | Train Acc: 81.67\n",
      "\n",
      "Epoch 52/100\n",
      "----------\n",
      "Train Loss: 0.4032 | Train Acc: 83.50\n",
      "\n",
      "Epoch 53/100\n",
      "----------\n",
      "Train Loss: 0.4240 | Train Acc: 83.42\n",
      "\n",
      "Epoch 54/100\n",
      "----------\n",
      "Train Loss: 0.4085 | Train Acc: 83.92\n",
      "\n",
      "Epoch 55/100\n",
      "----------\n",
      "Train Loss: 0.3897 | Train Acc: 84.33\n",
      "Val Loss: 0.7796 | Val Acc: 66.67\n",
      "\n",
      "Epoch 56/100\n",
      "----------\n",
      "Train Loss: 0.4058 | Train Acc: 84.25\n",
      "\n",
      "Epoch 57/100\n",
      "----------\n",
      "Train Loss: 0.4001 | Train Acc: 84.83\n",
      "\n",
      "Epoch 58/100\n",
      "----------\n",
      "Train Loss: 0.3670 | Train Acc: 86.00\n",
      "\n",
      "Epoch 59/100\n",
      "----------\n",
      "Train Loss: 0.4205 | Train Acc: 83.25\n",
      "\n",
      "Epoch 60/100\n",
      "----------\n",
      "Train Loss: 0.3643 | Train Acc: 85.92\n",
      "Val Loss: 0.4283 | Val Acc: 87.33\n",
      "\n",
      "Epoch 61/100\n",
      "----------\n",
      "Train Loss: 0.3670 | Train Acc: 84.75\n",
      "\n",
      "Epoch 62/100\n",
      "----------\n",
      "Train Loss: 0.4348 | Train Acc: 82.58\n",
      "\n",
      "Epoch 63/100\n",
      "----------\n",
      "Train Loss: 0.4299 | Train Acc: 82.92\n",
      "\n",
      "Epoch 64/100\n",
      "----------\n",
      "Train Loss: 0.3698 | Train Acc: 84.83\n",
      "\n",
      "Epoch 65/100\n",
      "----------\n",
      "Train Loss: 0.3440 | Train Acc: 85.58\n",
      "Val Loss: 0.4212 | Val Acc: 84.67\n",
      "\n",
      "Epoch 66/100\n",
      "----------\n",
      "Train Loss: 0.3577 | Train Acc: 86.08\n",
      "\n",
      "Epoch 67/100\n",
      "----------\n",
      "Train Loss: 0.4005 | Train Acc: 84.67\n",
      "\n",
      "Epoch 68/100\n",
      "----------\n",
      "Train Loss: 0.3528 | Train Acc: 85.67\n",
      "\n",
      "Epoch 69/100\n",
      "----------\n",
      "Train Loss: 0.3506 | Train Acc: 85.17\n",
      "\n",
      "Epoch 70/100\n",
      "----------\n",
      "Train Loss: 0.3471 | Train Acc: 86.50\n",
      "Val Loss: 0.6765 | Val Acc: 75.33\n",
      "\n",
      "Epoch 71/100\n",
      "----------\n",
      "Train Loss: 0.3405 | Train Acc: 86.58\n",
      "\n",
      "Epoch 72/100\n",
      "----------\n",
      "Train Loss: 0.3670 | Train Acc: 85.58\n",
      "\n",
      "Epoch 73/100\n",
      "----------\n",
      "Train Loss: 0.3248 | Train Acc: 86.83\n",
      "\n",
      "Epoch 74/100\n",
      "----------\n",
      "Train Loss: 0.3378 | Train Acc: 86.08\n",
      "\n",
      "Epoch 75/100\n",
      "----------\n",
      "Train Loss: 0.3221 | Train Acc: 88.00\n",
      "Val Loss: 0.5164 | Val Acc: 85.33\n",
      "\n",
      "Epoch 76/100\n",
      "----------\n",
      "Train Loss: 0.3862 | Train Acc: 84.33\n",
      "\n",
      "Epoch 77/100\n",
      "----------\n",
      "Train Loss: 0.3562 | Train Acc: 85.67\n",
      "\n",
      "Epoch 78/100\n",
      "----------\n",
      "Train Loss: 0.3228 | Train Acc: 86.83\n",
      "\n",
      "Epoch 79/100\n",
      "----------\n",
      "Train Loss: 0.2912 | Train Acc: 89.17\n",
      "\n",
      "Epoch 80/100\n",
      "----------\n",
      "Train Loss: 0.2924 | Train Acc: 87.75\n",
      "Val Loss: 0.8972 | Val Acc: 68.67\n",
      "\n",
      "Epoch 81/100\n",
      "----------\n",
      "Train Loss: 0.3110 | Train Acc: 87.08\n",
      "\n",
      "Epoch 82/100\n",
      "----------\n",
      "Train Loss: 0.3425 | Train Acc: 87.25\n",
      "\n",
      "Epoch 83/100\n",
      "----------\n",
      "Train Loss: 0.2687 | Train Acc: 89.25\n",
      "\n",
      "Epoch 84/100\n",
      "----------\n",
      "Train Loss: 0.2667 | Train Acc: 89.08\n",
      "\n",
      "Epoch 85/100\n",
      "----------\n",
      "Train Loss: 0.3026 | Train Acc: 89.00\n",
      "Val Loss: 0.5362 | Val Acc: 78.00\n",
      "\n",
      "Epoch 86/100\n",
      "----------\n",
      "Train Loss: 0.2987 | Train Acc: 88.75\n",
      "\n",
      "Epoch 87/100\n",
      "----------\n",
      "Train Loss: 0.3012 | Train Acc: 88.42\n",
      "\n",
      "Epoch 88/100\n",
      "----------\n",
      "Train Loss: 0.2857 | Train Acc: 89.25\n",
      "\n",
      "Epoch 89/100\n",
      "----------\n",
      "Train Loss: 0.3379 | Train Acc: 86.25\n",
      "\n",
      "Epoch 90/100\n",
      "----------\n",
      "Train Loss: 0.3134 | Train Acc: 88.25\n",
      "Val Loss: 0.5560 | Val Acc: 84.00\n",
      "\n",
      "Epoch 91/100\n",
      "----------\n",
      "Train Loss: 0.2962 | Train Acc: 88.58\n",
      "\n",
      "Epoch 92/100\n",
      "----------\n",
      "Train Loss: 0.3297 | Train Acc: 87.58\n",
      "\n",
      "Epoch 93/100\n",
      "----------\n",
      "Train Loss: 0.2664 | Train Acc: 89.75\n",
      "\n",
      "Epoch 94/100\n",
      "----------\n",
      "Train Loss: 0.2511 | Train Acc: 91.00\n",
      "\n",
      "Epoch 95/100\n",
      "----------\n",
      "Train Loss: 0.2582 | Train Acc: 89.42\n",
      "Val Loss: 0.6419 | Val Acc: 78.00\n",
      "\n",
      "Epoch 96/100\n",
      "----------\n",
      "Train Loss: 0.2260 | Train Acc: 92.33\n",
      "\n",
      "Epoch 97/100\n",
      "----------\n",
      "Train Loss: 0.2959 | Train Acc: 88.33\n",
      "\n",
      "Epoch 98/100\n",
      "----------\n",
      "Train Loss: 0.2761 | Train Acc: 89.25\n",
      "\n",
      "Epoch 99/100\n",
      "----------\n",
      "Train Loss: 0.3013 | Train Acc: 88.92\n",
      "\n",
      "Epoch 100/100\n",
      "----------\n",
      "Train Loss: 0.3031 | Train Acc: 87.75\n",
      "Val Loss: 0.4579 | Val Acc: 86.67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, validation_loadder, num_epochs=100, learning_rate=0.7e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"Data/params/best_model_tLoss0.36_tAcc85.92_vAcc87.33.pt\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"Data/Params/best_model_tLoss0.36_vAcc87.33.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"Data/params/best_model_loss0.31_vAcc88(for further training).pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_confusion(predictions, labels):\n",
    "  predictions = predictions.numpy(force=True)\n",
    "  labels = labels.numpy(force=True)\n",
    "  for x, y in zip(labels, predictions):\n",
    "    arr[x][y] += 1\n",
    "  return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_array(arr):\n",
    "  # v labels\n",
    "  # > predictions\n",
    "\n",
    "  ws = len(max(train_dataset.classes, key=len))\n",
    "  print(f\"%{ws}s |\" %(\"\"), end = ' ')\n",
    "\n",
    "  for x in train_dataset.classes:\n",
    "    print(\"%s |\" % (x), end = ' ')\n",
    "  print(\"\\n\")\n",
    "\n",
    "  for x in range(3):\n",
    "    print(f\"%{ws}s |\" % (train_dataset.classes[x]), end = ' ')\n",
    "    for y in range(3):\n",
    "      print(f\"%{len(train_dataset.classes[y])}.d |\" % (arr[x][y]), end = ' ')\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 85.33%\n",
      "\n",
      "\n",
      "      | bird | car | house | \n",
      "\n",
      " bird |   46 |   1 |     3 | \n",
      "\n",
      "  car |    5 |  41 |     4 | \n",
      "\n",
      "house |    7 |   2 |    41 | \n",
      "\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[0, 0, 0], [0, 0, 0], [0, 0, 0]])\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in test_loader:\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predicted = predicted.to(device)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        calculate_confusion(predicted, labels)\n",
    "\n",
    "    print('Accuracy on the test set: {:.2f}%'.format(100 * correct / total))\n",
    "    print(\"\\n\")\n",
    "    print_array(arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
